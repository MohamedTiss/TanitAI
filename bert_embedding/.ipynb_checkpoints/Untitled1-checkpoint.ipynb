{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a2a2444-914e-4eb9-b5b8-46ee058f76ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d9ae47c-818f-4ec8-aad3-388feae87fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neo4j connection details\n",
    "NEO4J_URI = \"bolt://localhost:7687\"  # Update with your Neo4j URI\n",
    "NEO4J_USER = \"neo4j\"  # Update with your username\n",
    "NEO4J_PASSWORD = \"testtest\"  # Update with your password\n",
    "NEO4J_DATABASE = \"test\"  # Specify your database name here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff524c69-a75b-4312-b746-8a40e0ba0798",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphRAG:\n",
    "    def __init__(self, uri, user, password, database):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "        self.database = database\n",
    "    \n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "    \n",
    "    def fetch_nodes(self):\n",
    "        query = \"MATCH (n) RETURN n.id AS id, n.text AS text\"\n",
    "        with self.driver.session(database=self.database) as session:\n",
    "            result = session.run(query)\n",
    "            nodes = [{\"id\": record[\"id\"], \"text\": record[\"text\"]} for record in result]\n",
    "        return nodes\n",
    "    \n",
    "    def store_embeddings(self, embeddings):\n",
    "        with self.driver.session(database=self.database) as session:\n",
    "            for node_id, embedding in embeddings.items():\n",
    "                query = \"\"\"\n",
    "                MATCH (n {id: $id})\n",
    "                SET n.embedding = $embedding\n",
    "                \"\"\"\n",
    "                session.run(query, id=node_id, embedding=embedding.tolist())\n",
    "    \n",
    "    def fetch_embeddings(self):\n",
    "        query = \"MATCH (n) WHERE exists(n.embedding) RETURN n.id AS id, n.embedding AS embedding\"\n",
    "        with self.driver.session(database=self.database) as session:\n",
    "            result = session.run(query)\n",
    "            embeddings = {record[\"id\"]: np.array(record[\"embedding\"]) for record in result}\n",
    "        return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fa66c5d-360b-48ec-84a9-d367138cbe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bert_embeddings(texts):\n",
    "    # Load pre-trained BERT model and tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    embeddings = {}\n",
    "    for node_id, text in texts.items():\n",
    "        # Tokenize input text\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            # Use the [CLS] token's representation as the embedding\n",
    "            cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "            embeddings[node_id] = cls_embedding\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1229a231-7653-4cee-8796-0bc1d583b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(embeddings):\n",
    "    node_ids = list(embeddings.keys())\n",
    "    vectors = np.array(list(embeddings.values()))\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarity_matrix = cosine_similarity(vectors)\n",
    "\n",
    "    similar_pairs = []\n",
    "    for i in range(len(node_ids)):\n",
    "        for j in range(i + 1, len(node_ids)):\n",
    "            similarity = similarity_matrix[i, j]\n",
    "            if similarity > 0.8:  # Threshold for similarity\n",
    "                similar_pairs.append((node_ids[i], node_ids[j], similarity))\n",
    "    return similar_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18fc762b-744a-4946-a9be-06393bd72b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_similarity_edges(graph_rag, similar_pairs):\n",
    "    with graph_rag.driver.session(database=graph_rag.database) as session:\n",
    "        for id1, id2, similarity in similar_pairs:\n",
    "            query = \"\"\"\n",
    "            MATCH (a {id: $id1}), (b {id: $id2})\n",
    "            MERGE (a)-[:SIMILAR {score: $similarity}]->(b)\n",
    "            \"\"\"\n",
    "            session.run(query, id1=id1, id2=id2, similarity=similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3bc56e6-0457-439f-acae-a68901c8922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_rag = GraphRAG(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD, NEO4J_DATABASE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4aaba15a-49b7-45de-bc0d-d699ad7cc35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: text)} {position: line: 1, column: 32, offset: 31} for query: 'MATCH (n) RETURN n.id AS id, n.text AS text'\n"
     ]
    }
   ],
   "source": [
    "nodes = graph_rag.fetch_nodes()\n",
    "node_texts = {node[\"id\"]: node[\"text\"] for node in nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba248f64-6234-4140-a0e9-86b45af83f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Connect to Neo4j\n",
    "    graph_rag = GraphRAG(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD, NEO4J_DATABASE)\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Fetch nodes from Neo4j\n",
    "        nodes = graph_rag.fetch_nodes()\n",
    "        node_texts = {node[\"id\"]: node[\"text\"] for node in nodes}\n",
    "\n",
    "        # Step 2: Generate BERT embeddings\n",
    "        embeddings = generate_bert_embeddings(node_texts)\n",
    "\n",
    "        # Step 3: Store embeddings back to Neo4j\n",
    "        graph_rag.store_embeddings(embeddings)\n",
    "\n",
    "        # Step 4: Fetch embeddings for similarity computation\n",
    "        stored_embeddings = graph_rag.fetch_embeddings()\n",
    "\n",
    "        # Step 5: Compute similarity\n",
    "        similar_pairs = compute_similarity(stored_embeddings)\n",
    "\n",
    "        # Step 6: Add similarity edges to Neo4j\n",
    "        add_similarity_edges(graph_rag, similar_pairs)\n",
    "\n",
    "        print(f\"Added {len(similar_pairs)} similarity relationships to the graph.\")\n",
    "    \n",
    "    finally:\n",
    "        # Close the Neo4j connection\n",
    "        graph_rag.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267f3075-0ce7-499d-96b3-24d1852e91cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import groq\n",
    "\n",
    "# Define Neo4j connection details\n",
    "uri = \"bolt://localhost:7687\"  # Change if necessary\n",
    "username = \"neo4j\"  # Replace with your Neo4j username\n",
    "password = \"testtest\"  # Replace with your Neo4j password\n",
    "database = \"test2\"  # Replace with your database name if different\n",
    "\n",
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Function to get embeddings from BERT\n",
    "def get_bert_embedding(text):\n",
    "    # Tokenize the input text and convert to tensor\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Extract the embeddings from the last hidden state\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)  # Mean pooling\n",
    "    return embeddings\n",
    "\n",
    "def get_all_node_embeddings():\n",
    "    with driver.session(database=database) as session:\n",
    "        # Modify query to fetch node properties, relationships, and connected nodes\n",
    "        result = session.run(\"\"\"\n",
    "            MATCH (n)-[r]->(m)\n",
    "            WHERE n.embedding IS NOT NULL \n",
    "            RETURN id(n) as node_id, n.embedding as embedding, n.name as name, \n",
    "                   n.properties as node_properties, n.type AS node_type,\n",
    "                   r.type AS relationship_type, \n",
    "                   m.name AS connected_node_name, m.labels AS connected_node_labels\n",
    "        \"\"\")\n",
    "        \n",
    "        node_embeddings = []\n",
    "        node_ids = []\n",
    "        node_names = []\n",
    "        node_types = []\n",
    "        node_properties = []\n",
    "        relationships_info = []\n",
    "        connected_node_names = []\n",
    "        connected_node_labels = []  # List to store labels of connected nodes\n",
    "        \n",
    "        for record in result:\n",
    "            node_ids.append(record[\"node_id\"])\n",
    "            node_embeddings.append(record[\"embedding\"])  # embeddings are stored as lists\n",
    "            node_names.append(record[\"name\"])\n",
    "            node_types.append(record[\"node_type\"])\n",
    "            node_properties.append(record[\"node_properties\"])\n",
    "            relationships_info.append(record[\"relationship_type\"])\n",
    "            connected_node_names.append(record[\"connected_node_name\"])\n",
    "            connected_node_labels.append(record[\"connected_node_labels\"])  # Store connected node labels\n",
    "        \n",
    "        return node_ids, np.array(node_embeddings), node_names, node_types, node_properties, relationships_info, connected_node_names, connected_node_labels\n",
    "\n",
    "# Function to find the most similar nodes based on query\n",
    "def find_similar_nodes(query_text, top_n=5):\n",
    "    # Generate the query embedding\n",
    "    query_embedding = generate_query_embedding(query_text)\n",
    "    \n",
    "    # Get all node embeddings and names from Neo4j\n",
    "    node_ids, node_embeddings, node_names, node_types, node_properties, relationships_info, connected_node_names, connected_node_labels = get_all_node_embeddings()\n",
    "    \n",
    "    # Calculate cosine similarities between the query embedding and all node embeddings\n",
    "    similarities = cosine_similarity([query_embedding], node_embeddings)[0]\n",
    "    \n",
    "    # Get top N most similar nodes\n",
    "    top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "    similar_nodes = []\n",
    "    for i in top_indices:\n",
    "        similar_nodes.append({\n",
    "            \"node_id\": node_ids[i],\n",
    "            \"node_name\": node_names[i],\n",
    "            \"node_type\": node_types[i],\n",
    "            \"similarity_score\": similarities[i],\n",
    "            \"node_properties\": node_properties[i],\n",
    "            \"relationships\": relationships_info[i],\n",
    "            \"connected_node_name\": connected_node_names[i],\n",
    "            \"connected_node_labels\": connected_node_labels[i],  # Include connected node labels\n",
    "        })\n",
    "    \n",
    "    return similar_nodes\n",
    "\n",
    "# Function to fetch detailed node information by id\n",
    "def get_node_details_by_id(node_id):\n",
    "    with driver.session(database=database) as session:\n",
    "        # Query to get detailed node information by node_id and relationships involving the node\n",
    "        result = session.run(\"\"\"\n",
    "            MATCH (n)-[r]->(m)\n",
    "            WHERE id(n) = $node_id\n",
    "            RETURN r, m.name AS connected_node_name, m.labels AS connected_node_labels\n",
    "        \"\"\", node_id=node_id)\n",
    "        \n",
    "        relationships = []\n",
    "        connected_nodes = []\n",
    "        for record in result:\n",
    "            relationships.append({\n",
    "                \"type\": record[\"r\"].type,  # Store relationship type\n",
    "                \"connected_node_name\": record[\"connected_node_name\"],\n",
    "                \"connected_node_labels\": record[\"connected_node_labels\"]\n",
    "            })\n",
    "        \n",
    "        return relationships\n",
    "\n",
    "# Function to generate query embedding\n",
    "def generate_query_embedding(query_text):\n",
    "    query_embedding = get_bert_embedding(query_text)\n",
    "    return query_embedding.squeeze().detach().numpy()\n",
    "\n",
    "# Function to print similar nodes with their names, scores, and properties\n",
    "def print_similar_nodes(query_text, top_n=5):\n",
    "    similar_nodes = find_similar_nodes(query_text, top_n)\n",
    "    \n",
    "\n",
    "# Function to query LLM with a detailed node description and query text\n",
    "# Function to query LLM with a detailed node description and query text\n",
    "def query_llm_with_node_context(query_text, node_info, relationships):\n",
    "    \"\"\"\n",
    "    Generate a detailed context for the LLM, including both the query and the node description,\n",
    "    then query the LLM for an answer based on the provided context.\n",
    "\n",
    "    Parameters:\n",
    "        query_text (str): The user's query text.\n",
    "        node_info (dict): Information about the node.\n",
    "            - node_name: Name of the node.\n",
    "            - node_type: Type of the node (optional).\n",
    "            - node_properties: Additional properties of the node (optional).\n",
    "        relationships (list of dict): Information about relationships connected to the node.\n",
    "            Each dict contains:\n",
    "            - type: Type of relationship.\n",
    "            - connected_node_name: Name of the connected node.\n",
    "\n",
    "    Returns:\n",
    "        str: The response from the LLM answering the query based on the context.\n",
    "    \"\"\"\n",
    "    # Create a conversational node description\n",
    "    node_description = (\n",
    "        f\"Here’s what I found about the node:\\n\\n\"\n",
    "        f\"- **Name**: {node_info.get('node_name', 'Unknown')}\\n\"\n",
    "        f\"- **Type**: {node_info.get('node_type', 'Not specified')}\\n\"\n",
    "        f\"- **Properties**: {node_info.get('node_properties', 'No additional properties listed')}\\n\\n\"\n",
    "        f\"It’s connected to the following nodes through these relationships:\\n\"\n",
    "    )\n",
    "\n",
    "    if relationships:\n",
    "        for relationship in relationships:\n",
    "            node_description += (\n",
    "                f\"  • Relationship Type: {relationship['type']}\\n\"\n",
    "                f\"    Connected Node: {relationship['connected_node_name']}\\n\"\n",
    "            )\n",
    "    else:\n",
    "        node_description += \"  (No relationships found)\\n\"\n",
    "\n",
    "    \n",
    "    # Inform the LLM that information has been gathered using a Neo4j graph\n",
    "    prompt = (\n",
    "        f\"Query: {query_text}\\n\\n\"\n",
    "        f\"I have used a Neo4j graph database to find relevant information related to this query.\\n\"\n",
    "        f\"Here’s the information I found about the relevant node:\\n\\n\"\n",
    "        f\"{node_description}\\n\"\n",
    "        f\"please answer the query using the provided context.\"\n",
    "    )\n",
    "\n",
    "    # Initialize Groq client\n",
    "    client = groq.Client(api_key=\"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\")\n",
    "\n",
    "    # Query the LLM for an answer based on the query and node context\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        model=\"llama-3.3-70b-versatile\"\n",
    "    )\n",
    "\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "   \n",
    "# Main function to execute the process\n",
    "def main():\n",
    "    query_text = \"node patient that suffers from Hypertension condition\"\n",
    "    print_similar_nodes(query_text, top_n=1)\n",
    "    \n",
    "    # Get detailed information about the most similar node\n",
    "    similar_nodes = find_similar_nodes(query_text, top_n=1)\n",
    "    if similar_nodes:\n",
    "        node_info = similar_nodes[0]\n",
    "        \n",
    "        # Fetch detailed relationships for the most similar node\n",
    "        relationships = get_node_details_by_id(node_info['node_id'])\n",
    "        \n",
    "        \n",
    "        # Query the LLM with the detailed node information and query text\n",
    "        llm_response = query_llm_with_node_context(query_text, node_info, relationships)\n",
    "        print(f\"\\nLLM Response: {llm_response}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
